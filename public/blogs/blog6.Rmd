---
categories:
- ""
- ""
date: "2020-10-13"
description: ""
draft: false
image: pic08.jpg
keywords: ""
slug: blog6
title: General Social Survey
---

```{r, setup, include=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)

# default figure size
knitr::opts_chunk$set(
  fig.width=6.75, 
  fig.height=6.75,
  fig.align = "center"
)
```


```{r load-libraries, include=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(mosaic)
library(ggthemes)
library(lubridate)
library(here)
library(skimr)
library(janitor)
library(httr)
library(readxl)
library(vroom)
```


The [General Social Survey (GSS)](http://www.gss.norc.org/) gathers data on American society in order to monitor and explain trends in attitudes, behaviours, and attributes. Many trends have been tracked for decades, so one can see the evolution of attitudes, etc in American Society.


In this assignment we analyze data from the **2016 GSS sample data**, using it to estimate values of *population parameters* of interest about US adults. The GSS sample data file has 2867 observations of 935 variables, but we are only interested in very few of these variables and you are using a smaller file.


##Overview

We want to see how many people use each social media Platform but let us first look at the data

```{r, read_gss_data, cache=TRUE}
#Let's first read and change the data for the answers such as "Don't know","No answer", "Not applicable". We classified these kind of answers as "NA"

gss <- read_csv(here::here("data", "smallgss2016.csv"), 
                na = c("", "Don't know","No answer", "Not applicable"))

glimpse(gss)

```

First we will check how many people use snapchat

```{r}
#Calculate the proportions snapchat
prop_snap <- gss %>%
  filter(snapchat!="NA") %>% 
  group_by(snapchat) %>% 
  summarise(count = n()) %>% 
  mutate(prop_snap = count/sum(count)) 

#Print the results
prop_snap

```

To visualize let us plot a histogram.

```{r}
# Plot the proportions
plot_snap <- prop_snap %>%
  ggplot(aes(
    x = snapchat,
    y = prop_snap)) +
  
  #choose the color of columns
  geom_col(fill = "red") + 
  
  #add the theme
  theme_bw()+
  
    labs(
    #Add the title
    title = "Around 23% people in the survey use Snapchat",
    x = "",
    y = "Proportion") +
  NULL
  
plot_snap
```

Is the percentage higher for twitter?

```{r}
#Calculate the proportions snapchat
prop_twitter <- gss %>%
  filter(twitter!="NA") %>% 
  group_by(twitter) %>% 
  summarise(count = n()) %>% 
  mutate(prop_twitter = count/sum(count)) 

#Print the results
prop_twitter
```

To visualize let us plot a histogram.

```{r}
#Plot the calculated data
plot_twitter <- prop_twitter %>%
  ggplot(aes(
    x = twitter,
    y = prop_twitter)) +
  
  #choose the color of columns
  geom_col(fill = "red") +
  
  #add the theme
  theme_bw()+
  
  #add the titles and name of axis
  labs(
    title = "Even less people use Twitter - 19%",
    x = "",
    y = "Proportion") +
  NULL

plot_twitter
```

Finally, let's check how many people use instagram.

```{r}
#Calculate the proportions instagram
prop_ig <- gss %>%
  filter(instagrm!="NA") %>% 
  group_by(instagrm) %>% 
  summarise(count = n()) %>% 
  mutate(prop_ig = count/sum(count))

#Print the results
prop_ig
```

Let's visualize our results with the help of histogram

```{r}
#Plot
# plot it with instagram colors
plot_instagram <- prop_ig %>%
  ggplot(aes(
    x = instagrm,
    y = prop_ig)) +
  
  #add the color of the columns
  geom_col(fill = "red") + 
  
  #to be consistant add the same theme
  theme_bw() +

  labs(
    #add the title and name of axis
    title = "The favourite social platform is Instagram with around 31% people using it",
    x = "",
    y = "Proportion") +
  NULL

plot_instagram
```

Following will be creating 95% confidence intervals for population parameters. The variables we have are the following:

- hours and minutes spent on email weekly. The responses to these questions are recorded in the `emailhr` and `emailmin` variables. For example, if the response is 2.50 hours, this would be recorded as emailhr = 2 and emailmin = 30.

- `snapchat`, `instagrm`, `twitter`: whether respondents used these social media in 2016

- `sex`: Female - Male

- `degree`: highest education level attained

## Instagram and Snapchat, by sex

Can we estimate the *population* proportion of Snapchat or Instagram users in 2016? Let's find out

First, we create a  new variable, `snap_insta` that is *Yes* if the respondent reported using any of Snapchat (`snapchat`) or Instagram (`instagrm`), and *No* if not. If the recorded value was NA for both of these questions, the value in your new variable should also be NA.

```{r, nap_insta, cache=TRUE}
#Create new variable

gss2 <- gss %>% 
  
  #create new column in the data set with the function mutate
  
mutate(snap_insta = case_when(snapchat == "Yes" ~ "Yes", 
                              instagrm == "Yes" ~ "Yes", is.na(snapchat) & 
                                is.na(instagrm) ~ "NA_character_",
                              snapchat == "No" & instagrm == "No" ~ "No"))               
  
```

Secondly, we calculate the proportion of Yes’s for `snap_insta` among those who answered the question, i.e. excluding NAs.

```{r, nap_insta2, cache=TRUE}

proportion_users <- gss2 %>% 
  
  #filter out NAs with the function filter
  
  filter(!is.na(snap_insta)) %>% 
  
  #summarise and create the proportion of yes
  
  summarise( 
    InstaSnap_Users = count(snap_insta == "Yes"),
    Non_Users = count(snap_insta == "No"),
    Proportion = InstaSnap_Users/ (InstaSnap_Users + Non_Users)
    )

#Print the reults
proportion_users
  
```

Proportion if people with snapchat or instagram is about 37.5%.

**Confidence intervals**

Using the CI formula for proportions, we construct 95% CIs for men and women who used either Snapchat or Instagram

```{r, nap_insta3, cache=TRUE}
 #Create new variable

proportion_users_gender <- gss2 %>% 
  
  #filter out NAs with the help of function filter
  
  filter(!is.na(snap_insta)) %>% 
  
  #group by gender
  
  group_by(sex) %>% 
  
  #use summarise function for the calculation of statistics
  
  summarise(
    InstaSnap_Users = count(snap_insta == "Yes"),
    Non_Users = count(snap_insta == "No"),
    Count = n(),
    Proportion = InstaSnap_Users/ (InstaSnap_Users + Non_Users)
    )

proportion_users_gender  # proportion - proportion_yes / count of original value

#With the new variable we can calculate our confidance interval
proportions_gender_ci <- proportion_users_gender %>% 
  summarise(
    proportion = Proportion,
    size = Count,
    SE = sqrt((proportion*(1-proportion))/size),
    tcritical = qt(0.975, size-1),
    lower_ci = proportion - tcritical*SE,
    upper_ci = proportion + tcritical*SE
  )

#Print results
proportions_gender_ci
  
```
The proportion of men who use snapchat or instagram seems to be of about 32%, whereas the proportion of men is 42%. The women's confidence interval goes from 38.4% to 45.4%, whereas men's interval goes from 28.1% to 35.6%.

## Twitter, by education level

**Can we estimate the *population* proportion of Twitter users by education level in 2016?** 

There are 5 education levels in variable `degree` which, in ascneding order of years of education, are Lt high school, High School, Junior college, Bachelor, Graduate. 

First, we will turn `degree` from a character variable into a factor variable. We made sure that the order is the correct one and that levels are not sorted alphabetically which is what R by default does. 

```{r, nap_twitter, cache=TRUE}

#Turn degree character variable into degree factor variable with the help of the function mutate

factor_degree<- gss %>% 
  
  #Exclude NAs
  na.omit(degree) %>% 
  
  mutate(degree = factor(degree, 
                         levels = c("Lt high school", 
                                    "High School", 
                                    "Junior college", 
                                    "Bachelor", 
                                    "Graduate"))) %>% 
  #arrange in order
  arrange((degree))

#Print our new data set

factor_degree

```

Secondly, we create a  new variable, `bachelor_graduate` that is *Yes* if the respondent has either a `Bachelor` or `Graduate` degree. As before, if the recorded value for either was NA, the value in your new variable should also be NA.

```{r, nap_twitter2, cache=TRUE}
#Create new variable bachelor_graduate

bachelor_graduate <-factor_degree%>%
  mutate(bachelor_graduate = case_when(
    degree == "Bachelor" ~ "Yes",
    degree == "Graduate" ~ "Yes",
    degree != "Graduate"& degree != "Bachelor" ~ "No",
    
    #Else
    
    TRUE ~ "NA"
  ))

#print results

print(bachelor_graduate)
```
Our data set is prepared.


In the next step we calculate the proportion of `bachelor_graduate` who do (Yes) and who don't (No) use twitter. 

```{r, nap_twitter3, cache=TRUE}
#Create new variable

proportion_twitter_bachelor_graduate <- bachelor_graduate %>%
  
  #Filter fot the bachelor_graduate who use twitter
  
  filter(bachelor_graduate =="Yes") %>% 
  
  #count twitter users
  
  count(twitter)%>% 
  
  #with the help of function pivot_wider we make the data set wider by increasing the number of columns
  
  pivot_wider(names_from=twitter , values_from=n) %>% 
  
  #we calculate the proportions with the help of function mutate
  
  mutate(twitter_yes= Yes/(No+Yes), twitter_no= No/(Yes+No))

#print the results

print(proportion_twitter_bachelor_graduate)
  
```

We can see that the chance that people who attended bachelor programs or graduated do not use twitter is 76%, whereas 24% do use it. 

Using the CI formula for proportions, we constructed two 95% CIs for `bachelor_graduate` vs whether they use (Yes) and don't (No) use twitter.

```{r, nap_twitter4, cache=TRUE}

confidence_interval_twitter_yes <- proportion_twitter_bachelor_graduate %>% 
  
  #95% confidence interval calculations for people who use twitter
  
  mutate(SE=sqrt((twitter_yes*(1-twitter_yes)/(Yes+No)))) %>% 
  summarise(lower_95=twitter_yes-1.96*SE, upper_95=twitter_yes+1.96*SE) %>% 
  summarise(CI_Yes_Twitter=c(lower_95,upper_95))

confidence_interval_twitter_yes

  #95% confidence interval calculations for people who use twitter

confidence_interval_twitter_no <- proportion_twitter_bachelor_graduate %>% 
  mutate(SE=sqrt((twitter_no*(1-twitter_no)/(Yes+No)))) %>% 
  summarise(lower_95=twitter_no-1.96*SE, upper_95=twitter_no+1.96*SE) %>% 
  summarise(CI_No_Twitter=c(lower_95,upper_95))

confidence_interval_twitter_no

```

>Two Conidence Intervals do not overlap. That means that the difference between Bachelor graduates who use (YES) and do not use (NO) is statistically significant.

## Email usage

Can we estimate the *population* parameter on time spent on email weekly?

First, we create a new variable called `email` that combines `emailhr` and `emailmin` to reports the number of minutes the respondents spend on email weekly.

```{r, nap_email1, cache=TRUE}
#new varible email

email <- gss %>%
  
  #with help of function mutate_at change variable to numeric
  
  mutate_at(vars(emailhr,emailmin), funs(as.numeric)) %>% 
  
  #create new total time in minutes
  
  mutate(email=(emailhr*60)+emailmin) %>% 
  
  #arrange in descending order
  
  arrange(desc(email))

#Print the new variable

email

```


If we want to visualise the distribution of this new variable, we need to find the mean and the median number of minutes respondents spend on email weekly. 

```{r, nap_email2, cache=TRUE}
#Let's do a summary of statistics

summary_email <- email %>%
  
  #clear NAs
   na.omit(email) %>%
  
  #summarize function helps us to summarize data
  
  summarize(mean = mean(email), median = median(email)) 

#print the summary data
summary_email


#Let's see how the density plot looks like

ggplot(email, aes(y=email)) +
  
  geom_boxplot()+
  scale_y_log10() +
  
  #add theme
  
  theme_bw()+
  
  #add title and name of axis and source
  labs(title="US Adults spend more than 100 Minutes on Emails a Week!",
       y="Email Minutes",
       caption="General Social Survey"
       )

```

Is the mean or the median a better measure of the typical amoung of time Americans spend on email weekly? Why?

Whenever a graph falls on a normal distribution, using the mean is a good choice. But if your data has extreme scores (such as the difference between a someone spends 6000 minutes and someone who spends 100 minutes at email a week), you will need to look at median, because we find a much more representative number for our data.

Using the `infer` package, we calculate a 95% bootstrap confidence interval for the mean amount of time Americans spend on email weekly. We interpreted this interval in context of the data, reporting its endpoints in “humanized” units (e.g. instead of 108 minutes, report 1 hr and 8 minutes).

```{r, nap_email3, cache=TRUE}
#donwload of the infer package
library(infer)

#calculation of the 95% bootstrap confidence interval

bootstrap_email_ci <- email %>% 
  specify(response = email) %>% 
  generate(reps = 100, type="bootstrap") %>% 
  calculate(stat = "mean") %>% 
  get_confidence_interval(level = 0.95, type = "percentile") %>% 
  
  # transform from min into h + min as decimal
  
  mutate(lower_ci = lower_ci/60, upper_ci = upper_ci/60) 

bootstrap_email_ci

```

The confidence interval for the mean email usage in the population is between 6hrs 24min and 7hrs 28min. This seems like a reasonable interval given that the sample mean is 6hrs and 57min.

4. Would you expect a 99% confidence interval to be wider or narrower than the interval you calculated above? Explain your reasoning.

If we were to increase the confidence level of the interval to 99%, then the range of the interval would increase. Increasing the confidence will increase the margin of error resulting in a wider interval. In general, the greater the confidence level, the greater the range between the high and low points in a confidence interval.
